---
title: Social Media’s Impact on Misinformation, Manipulation, and Propaganda Campaigns
author: Yiğit Küçük
date: 2022-05-08 14:10:00 +0800
categories: [English Research Paper, Academic]
tags: [Social Media, Propaganda]
render_with_liquid: false
---

## Social Media’s Impact on Misinformation, Manipulation, and Propaganda Campaigns

In the era of Web 2.0 of the internet, it is evident that the user is the creator and the consumer of the media. This internet property encouraged a participation culture, resulting in the creation of content and distribution of information more expeditious than ever. The more information the social media platform contains, the harder it is for the owners to keep track of cases of disinformation and propaganda. Indeed, social media companies rely on algorithms to keep their platforms safe from these harmful effects, but these algorithms are shown to be manipulated easily.[^1] Social media platforms prefer not to fix those problems to profit more, or they cannot fix them, as there have been attempts from social media platforms such as Facebook to reduce fake news, but then revoked for unknown reasons.[^2] Social media platforms serve as a container for misinformation[^3], propaganda[^4], echo chambers[^5], and manipulation[^6]. As consequences of misinformation on social media are less than in traditional media, opinion leaders utilize social
media to spread their propaganda.[^7] Salting the wound from the conventional media days, people start to lose their trust in specific legitimate sources on social media[^8] and lean towards more isolated sources and choose to trust them.[^9] So they are pushed to become close-minded to others groups' ideas and follow like-minded people, trapping them in an echo chamber with the help of algorithmic filtering.[^10]
Mass communication through echo chambers, propaganda campaigns, misinformation, and advertisements by opinion leaders and influencers on social media is shown to be effective in controlling the public.[^11] By employing these techniques, corporations increase their revenue, opinion leaders gain money and control, and the public loses the sense of questioning. As the capital gains more power with these processes, the more strength it acquires, and the more dependent on social media and opinion leaders the people become. Since the transition from traditional media to social media started, opinion leaders gained a chance to create echo chambers around themselves and misinform people more efficiently, spread their propaganda to larger audiences, and prepare an uncritical, non-thinking, and more easily manipulated society for their benefits.


### Herman and Chomsky's Propaganda Model in the Age of the Internet

To better understand how propaganda is exercised in social media, we should look into Herman and Chomsky's Propaganda Model, as Christian Fuchs did.[^12] Even though the model was proposed over thirty years ago, it is still applicable to social media platforms and internet news sources like any other medium or information source.[^13] It relies on these five filters: ownership and profit orientation, advertising, sourcing, mediated lobbying, and ideologies.[^14] These five filters are substantial to understanding how our news feed or the trending pages of social media platforms take shape. The critical point of Herman and Chomsky's model is that wealth and power inequalities mainly decide what is considered newsworthy, what gets censored, what gets reported, and what is heard, read, and watched.[^15] These five filters featured in the model demonstrate how social media platforms can be used as a means of propaganda, misinformation, manipulation, or monetization.
The ownership filter indicates that private ownership of the platforms hides the control of algorithms that decrees the priorities of how search results and news are presented.[^16] Social media platforms have the right to keep their algorithms as corporate secrets[^17], and thus, they cannot be charged for prioritizing specific propaganda channels with their algorithms.
Advertisement filter inspects targeted ads and the primary income of news sources.[^18] What we are shown on social media depends on our engagement with specific groups in social media and what the people we are similar to are interested in.[^19] This way, social media algorithms categorize people; a person interested in religions may see an Evangelist promoted post, whereas a person interested in politics may see a politician's promoted post. As will be explained later, the categorization of users essentially creates echo chambers and a homophily effect. Besides, social media news sources' primary income is advertisements or government funding, so social media platforms reshape their policies and algorithms in a way that they can keep advertisers as well as their funders.
The sourcing filter implies that the more money a news source has, the more reputation it has, and the better the chance of being prioritized.[^20] Sources with more followers will always be more prominent and have more advantages than independent news sources. Although everyone can produce content on the internet, only a tiny percentage can attract online attention because of the power inequalities.[^21]
The fourth filter, mediated lobbying, or as Herman and Chomsky put it, "flak[^22]" asserts that what we see in media is dependent on the possible backlash.[^23] Social media platforms may remove or shadow the content regardless of the righteousness of the information because of the fear of losing revenue.
The last filter is ideology. What we are shown on social media depends on the preponderant ideology in the social media platform.[^24] "Given that right-wing ideology is flourishing in many societies, it is also exceedingly present online and social media."[^25] The dominant ideology may differ from platform to platform, but it certainly affects the majority of the content and news.
Having acknowledged these five factors, it is more straightforward to comprehend how opinion leaders, advocacy groups, corporations, governments, and states can exercise propaganda on social media to manipulate the general public.

### Opinion Leaders, Advocacy Groups, and Propaganda on Social Media

Social media provides opinion leaders with tools to spread their propaganda to larger audiences more effectively. Although social media did not completely replace traditional media, it is used more regularly by a larger audience. "Currently, 72 percent of Americans get digital news primarily from a mobile device, and people now prefer online news sources to print sources by a two-to-one ratio."[^26] This is why controlling the narrative on social media has become essential to enforce propaganda on the general public. "Social media creates a point of injection for propaganda and has become the nexus of information operations and cyber warfare."[^27] States and advocacy groups have excessively used social networking sites like Twitter and Facebook to spread propaganda.
One of the reasons social media platforms like Twitter and Facebook are vulnerable to propaganda is their algorithms. Social media sites' trending algorithms (especially for Twitter) are weak against bots. So, propaganda can quickly spread to much larger audiences than traditional media. With bots, a group can insert propaganda into a social media platform, create a trend, and rapidly disseminate a message more swiftly, efficiently, and cheaper than any other medium.[^28]
On November 11, 2015, a Twitter user single-handedly spread the propaganda that KKK was marching toward Mizzou University's campus, using the already trending tag #PrayForMizzou which initially emerged because students wanted to gather attention to the racial inequalities. He made Twitter users believe that KKK was marching toward the campus with only a few tweets from fake accounts and turned the tag into a means of spreading propaganda. People quickly started to buy his story and spread misinformation. The user was not even living in the United States, let alone Missouri.[^29] This example alone demonstrates how easy it is to manipulate the algorithm of social media platforms, control the narrative, and thus, spread the propaganda. Bot accounts can be used to direct the trends on social media, they are cheap, and they are easy to purchase without any consequences.
Aside from bot accounts, governments, states, terrorist groups, and advocacy groups employ cyber troops. Cyber troops are publicly funded and often highly coordinated government actors who use social media to spread disinformation and attempt to generate false consensus.[^30] Governments utilize these cyber troops on social media to spread propaganda with high success rates. Cyber troops are generally used to discredit political opponents or gain a political advantage over opponents by using the general public's collective values. In 2016, one story stating that the pope endorsed Donald Trump for president received millions of shares and retweets on Facebook and Twitter.[^31] The consequences of such an outright lie would be harsher in traditional media, but there is little to no punishment for these acts in social media. Banned accounts are replaceable, and cyber troops are disposable, so propaganda spread is inevitable.
Another way of exercising propaganda on social media is hacking. The majority of the corporations, enterprises, and individuals still do not use encryption services, including high
officials and leaders of big advocacy groups, so they are not immune to hacking incidents. For example, Islamic State's "CyberCaliphate," hacked U.S. Central Command's Twitter and YouTube accounts in 2015 to spew propaganda.[^32] This and many other incidents like Twitch and Amazon's data leaks show that social media can be used to spread propaganda even if the user itself did not intend to do so. 
In conclusion, propaganda is spread with social media cheaper, more efficiently, and less effort than traditional media. Anyone can start a propaganda campaign with the proper steps; social media algorithms are vulnerable to bot attacks and fake accounts. Propaganda campaigns on social media, as will be talked about, will lead to a more apathetic, uncritical, and non-thinking society.

### Social media, misinformation, and Echo chambers

Since the transition from traditional media to social media started, opinion leaders gained a chance to create echo chambers around themselves and misinform people more efficiently. The echo chamber concept originated from theories such as homophily, selective exposure, the polarization of groups, and audience fragmentation, and Jamieson and Capella popularized it in 2008.[^33] Although the concept of echo chambers existed way before the term was defined, the effects of echo chambers became more evident with social networking sites. Social networking sites allow people with similar opinions to gather together more efficiently and avoid opposing ideas. According to a study by Del Vicario,[^34] selective content exposure forms homogeneous echo chambers. In contrast to traditional media, there is a community for every ideology, idea, interest, or political opinion in social media; for example, as of May 8, 2022, there are more than 3.4 million different communities on Reddit.[^35]
The more the characteristics of a group of individuals in these communities become similar, the more they are likely to form echo chambers. These echo chambers of like-minded people provide a breeding ground for information to spread and thus for creating media hypes.[^36] Besides, these groups eventually become isolated from society. Because they have limited access to opposing thoughts, they tend to become entrenched in their existing beliefs and less able to engage with other ideas in society.[^37]
Having understood what an echo chamber is and how it emerges, it is easier to comprehend how social media algorithms also contribute to the forming of echo chambers. "Stories arrive in the feeds algorithmically, meaning there is a filtering mechanism where certain of them are boosted, based on signals such as activity and increasingly trustworthiness, or the amount of given and measured meaningful engagement between individuals."[^38] In other words, users with similar engagement and opinions will be encouraged to interact with each other with social media algorithms.
These algorithms are dangerous because they promote homophily, but they are also dangerous because what we are exposed to on social media is directly in the corporation's hands. The centralized ownership of social media platforms, combined with the vast market share of users and the fact that social media platforms are essential news sources, results in the circumstance that the ownership of these platforms determines algorithms that determine news sources for a significant part of the population.[^39] Which opinion leaders users see or do not see is solely determined by the algorithms, and the platform owners can easily manipulate these algorithms. That is, owners of social media platforms thus may choose what kind of misinformation they allow on their platform.
While opinion leaders on social media can serve as a trusted source for information and therefore have the potential to insulate their followers from threats of problematic information flows on social media, they could also amplify the effects of disinformation and echo chambers if their political information verification practices are poor.[^40] The combination of a misinformed opinion leader and an echo chamber results in the spread of misinformation. As trust in social media platforms as an information source declined, concerns regarding disinformation and polarized echo chambers have increased.[^41] The more polarized the echo chambers become, the more people trust their opinion leaders. The more likely they will spread the ideas from their opinion leaders and people of similar opinions. This fragmentation in social media makes it harder to correct misinformed members of other groups and stop the misinformation wave on social networking platforms.
Echo chambers and algorithms are not the only reason misinformation spreads quickly on social media. The userbase of the social media platform is also relevant in understanding how information travels through social media. Research shows that "Confirmation bias is present, with participants more likely to believe headlines to be credible when they aligned with the user's political beliefs."[^42] Another study shows that opinion seekers on social media are more vulnerable to disinformation, and their fact-checking tendencies are much lower than opinion leaders.[^43] So, opinion leaders have the opportunity to use the vulnerability of their followers to spread misinformation, exercise propaganda, or even for monetization.
All in all, social media creates the perfect environment for people to form echo chambers and close their minds to opposing views. An increase in the number of echo chambers will hinder people from connecting with other ideas, which will result in polarization among different groups in society. Opinion leaders can profit from this fragmentation and polarization in the general public by gaining a medium to disinform people and spread their ideas and ideologies more efficiently.

### Monetization, Manipulation, and Critical Thinking in the Age of Web 2.0

Opinion leaders utilize social media to create an uncritical, non-thinking, and open-to- manipulation society to benefit from them. Of course, opinion leaders in traditional media also manipulate society and hinder them from thinking for themselves. However, these cases amplified with the transition to social media. Now, opinion leaders can gather a considerable part of society for the benefit of social media in a short amount of time. Social media sites will allow this for profit. The dominant social media platforms have concentrated ownership. Google co-founders Larry Page and Sergey Brin own 42.4% and 41.3% respectively of Alphabet's class B common stock."[^44] Social media platforms belong to individuals and corporations, and these individuals can allow propaganda and advertising for monetization even if it is harmful to society. "Google, Facebook, and Twitter are not just sources of news and information. These websites are also among the world's largest advertising agencies.[^45]
As talked about before, social media algorithms favor bots, cyber troops, and advertisers. The flaws in trending algorithms and moderation teams are not unsurmountable for these billions of dollars worth of companies. Social media sites like Twitter and Facebook have become the center of attention for politicians, advocacy groups, and advertisers. "In the digital age, lobbying for certain interests has been extended to social media and is no longer simply aimed at centralized media organizations, but now aims to directly transmit political messages to as many internet users as possible."[^46] The potential to capture an audience's attention is greater in social media than any other medium. For capital, it is important to control the narrative to achieve monopolization. It is easier than ever to achieve with influencers and opinion leaders in the internet age. "The news media are in crisis. Advertising has shifted from print towards targeted online ads."[^47] A good indicator is an increase in the share of online advertising from 17.9% to 28.3% in the years from 2010 until 2015.[^48] So, it is safe to say that online advertisements are the primary way for revenue for both brands, influencers, and social media platform owners.
Having understood the methodology of opinion leaders and advocacy groups to reach their audience, it becomes easier to understand their ways of monetization. According to the study, 77 % of consumers on the internet would take action following a recommendation from online user reviews, a family member, or a friend.[^49] Opinion leaders and influencers use their earned trust from their followers to take advertisements on their social media accounts, promote products they do not use in their personal lives, and create an illusion of affinity[^50] between themselves and their followers or audience. An example from 2014 is Duane Reade, a drugstore, who reached into blogger Donna Kim's network with her earned endorsement for the drugstore's leggings and tights, and her fans followed suit and shopped, resulting in %28 boosts in sales, believing that she genuinely liked the brand.[^51]
As opinion leaders are reputed to have richer knowledge about products in a specific range, they can vastly influence people's behavior towards a particular product by expressing their opinions.[^52] Corporations and influencers monetize and monopolize this way, and the public gets manipulated and deceived.
In summary, social media has become a place for corporations, advocacy groups, opinion leaders, and influencers to manipulate society and hinder their critical thinking by putting forward the brands to benefit them the most. Social media will form closer bonds with capitalism and further use society for growth.

### Conclusion

Since the transition from traditional media to social media started, opinion leaders gained the chance to create echo chambers around themselves and misinform people more efficiently, spread their propaganda to larger audiences, and prepare a non-thinking, uncritical, more easily manipulated society for their interests.
Suppose mainstream social media corporations continue allowing disinformation and propaganda on their platforms for profit. In that case, as implied by advertisement and ideology filters in Herman and Chomsky's model, the polarization of society will amplify, and people's reliance on each other will diminish. Using social media to give directions to trends will extend the effects and range of propaganda. As the ownership filter foresees, governments and big advocacy groups will continue to use social media to spread their propaganda, and owners of social media platforms will not put an end to these campaigns for the sake of monetization. Collective action against propaganda and disinformation campaigns will be unlikely as the general public will be fragmented due to echo chambers. As the mediated lobbying filter asserts, any opposition against the current trend by an individual or a group will face the consequences. Governments will continue to benefit from social media because they have the power of money on their side, as the sourcing filter implies; in this case, we should take individual steps. We should reconsider our fact- checking habits and make sure we are open to other thought groups' ideas.
Moreover, we should be careful not to spread misinformation. We should not share, distribute or repost information without checking its validity. We must not follow opinion leaders or advocacy groups blindly. We must question their intentions before supporting them. This way, we can create our defensive mechanisms against the rising misinformation and propaganda campaigns without relying on big corporations and their algorithms to protect us.


### Bibliography

Swift, Art, “Americans’ Trust in Mass Media Sinks to New Low,” Gallup, 14 September 2016, http://news.gallup.com/poll/195542/americans-trust-mass-media-sinks-new- low.aspx.

Bossetta, Michael. “The Weaponization of Social Media: Spear Pishing and Cyberattacks on Democracy.” Journal of International Affairs 71, no. 1.5 (2018): 97–106. https://www.jstor.org/stable/26508123.


Bradshaw, Samantha, and Philip N. Howard. “The Global Organization of Social Media Disinformation Campaigns.” Journal of International Affairs 71, no. 1.5 (2018): 23–32. https://www.jstor.org/stable/26508115.


“Complete List of Subreddits.” frontpagemetrics. Accessed May 8, 2022. https://frontpagemetrics.com/list-all-subreddits.

Del Vicario, Michela, Alessandro Bessi, Fabiana Zollo, Fabio Petroni, Antonio Scala, Guido Caldarelli, H. Eugene Stanley, and Walter Quattrociocchi. “The Spreading of Misinformation Online.” Proceedings of the National Academy of Sciences of the United States of America 113, no. 3 (2016): 554–59. https://www.jstor.org/stable/26467425.


Dubois, Elizabeth, Sara Minaeian, Ariane Paquet-Labelle, and Simon Beaudry. “Who to Trust on Social Media: How Opinion Leaders and Seekers Avoid Disinformation and Echo Chambers.” Social Media + Society, no 3 (2020): 1–13. https://doi.org/10.1177/2056305120913993.


Fakhreddin, Farbod, and Pantea Foroudi. “Instagram Influencers: The Role of Opinion Leadership in Consumers’ Purchase Behavior.” Journal of Promotion Management, December 6, 2021, 1–31. doi:10.1080/10496491.2021.2015515.


Fuchs, Christian. “Propaganda 2.0: Herman and Chomsky’s Propaganda Model in the Age of the Internet, Big Data and Social Media.” In The Propaganda Model Today: Filtering Perception and Awareness, edited by Joan Pedro-Carañana, Daniel Broudy, and Jeffery
 
Klaehn, 8:71–92. University of Westminster Press, 2018. http://www.jstor.org/stable/j.ctv7h0ts6.8.


Herman, Edward S., and Noam Chomsky. Manufacturing Consent : The Political Economy of the Mass Media. 1st ed. Pantheon Books, 1988. https://search.ebscohost.com/ login.aspx? direct=true&db=cat00040a&AN=bilk.220692&site=eds-live.


Jegham, Salma, and Rym Bouzaabia. “Fashion Influencers on Instagram: Determinants and Impact of Opinion Leadership on Female Millennial Followers.” Journal of Consumer Behaviour 21, no 2 (2022): 1–16. doi:10.1002/cb.2050.


Johan Farkas. “Disguised Propaganda from Digital to Social Media.” In Second International	
 	Handbook of Internet Research, 1–17. Springer, 2018. https://doi.org/10.1007/978-94-024-


Jonathan A. Obar, Paul Zube, and Clifford Lampe. “Advocacy 2.0: An Analysis of How Advocacy Groups in the United States Perceive and Use Social Media as Tools for Facilitating Civic Engagement and Collective Action.” Journal of Information Policy 2, no 2. (2012): 1–25. https://doi.org/10.5325/jinfopoli.2.2012.0001.


Kapitan, Sommer, and David H. Silvera. “From Digital Media Influencers to Celebrity Endorsers: Attributions Drive Endorser Effectiveness.” Marketing Letters 27, no. 3 (2016): 553–67. http://www.jstor.org/stable/26179958.


Kitchens, Brent, Steven L. Johnson, and Peter Gray. “Understanding Echo Chambers and Filter Bubbles: The Impact of Social Media on Diversification and Partisan Shifts in News Consumption.” MIS Quarterly 44, no. 4 (December 2020): 1619–49. doi:10.25300/MISQ/2020/16371.


Kotler, Philip, and Gerald Zaltman. “Social Marketing: An Approach to Planned Social Change.”
Journal of Marketing 35, no. 3 (1971): 3–12. https://doi.org/10.2307/1249783.


Leber, Andrew, and Alexei Abrahams. “A Storm of Tweets: Social Media Manipulation During the Gulf Crisis.” Review of Middle East Studies 53, no. 2 (2019): 241–58. https://doi.org/doi:10.1017/rms.2019.45.
 
Moravec, Patricia L., Randall K. Minas, and Alan R. Dennis. “Fake News on Social Media: People Believe What They Want to Believe When It Makes No Sense at All.” MIS Quarterly 43, no. 4 (December 2019): 1343–60. doi:10.25300/MISQ/2019/15505.


Prier, Jarred. “Commanding the Trend: Social Media as Information Warfare.” Strategic Studies Quarterly 11, no. 4 (2017): 50–85. http://www.jstor.org/stable/26271634.


Roese, Vivian. “You Won’t Believe How Co-Dependent They Are: Or: Media Hype and the Interaction of News Media, Social Media, and the User.” In From Media Hype to Twitter Storm, edited by Peter Vasterman, 313–32. Amsterdam University Press, 2018. https://doi.org/10.2307/j.ctt21215m0.19.


Rogers, Richard, and Sabine Niederer. “The Politics of Social Media Manipulation.” In The Politics of Social Media Manipulation, 19–70. Amsterdam University Press, 2020.
https://doi.org/10.2307/j.ctv1b0fvs5.3.


Sabry, Tarik. “The Propaganda Model after 20 Years: Interview with Edward S. Herman and Noam Chomsky.” Westminster Papers in Communication and Culture 6, no. 2 (June 1, 2017). doi:10.16997/wpcc.121.


### Footnotes

[^1]:	Jarred Prier. “Commanding the Trend: Social Media as Information Warfare.” Strategic Studies Quarterly 11, no. 4 (2017): 68. http://www.jstor.org/stable/26271634.

[^2]:	Patricia L. Moravec, Randall K. Minas and Alan R. Dennis. “Fake News on Social Media: People Believe What They Want to Believe When It Makes No Sense at All.” MIS Quarterly 43, no. 4 (December 2019): 1345. doi:10.25300/MISQ/2019/15505.

[^3]:	Samantha Bradshaw and Philip N. Howard. “The Global Organization of Social Media Disinformation Campaigns.” Journal of International Affairs 71, no. 1.5 (2018): 23. https://www.jstor.org/stable/26508115.

[^4]: Prier, 70–73.

[^5]:	Vivian Roese. “You Won’t Believe How Co-Dependent They Are: Or: Media Hype and the Interaction of News Media, Social Media, and the User.” In From Media Hype to Twitter Storm, ed. by Peter Vasterman (Amsterdam University Press, 2018), 327–328. https://doi.org/10.2307/j.ctt21215m0.19.

[^6]:	Leber, Andrew and Alexei Abrahams. “A Storm of Tweets: Social Media Manipulation During the Gulf Crisis.” Review of Middle East Studies 53, no. 2 (2019): 246. doi:10.1017/rms.2019.45.

[^7]:	 Johan Farkas. “Disguised Propaganda from Digital to Social Media.” In Second International Handbook of Internet Research. (Springer, 2018), 6. https://doi.org/10.1007/978-94-024-1202- 4_33-1.

[^8]:	Art Swift, “Americans’ Trust in Mass Media Sinks to New Low,” Gallup, 14 September 2016, http://news.gallup.com/poll/195542/americans-trust-mass-media-sinks-new-low.aspx.

[^9]:	Prier, 60.

[^10]:	Brent Kitchens, Steven L. Johnson and Peter Gray. “Understanding Echo Chambers and Filter Bubbles: The Impact of Social Media on Diversification and Partisan Shifts in News Consumption.” MIS Quarterly 44, no. 4 (December 2020): 1621. doi:10.25300/MISQ/2020/16371.

[^11]:	Farbod Fakhreddin, and Pantea Foroudi. “Instagram Influencers: The Role of Opinion Leadership in Consumers’ Purchase Behavior.” Journal of Promotion Management, no 3 (2021): 5. doi:10.1080/10496491.2021.2015515.

[^12]:	Christian Fuchs. “Propaganda 2.0: Herman and Chomsky’s Propaganda Model in the Age of the Internet, Big Data and Social Media.” In The Propaganda Model Today: Filtering Perception and Awareness, (University of Westminster Press, 2018), 71–92. http://www.jstor.org/stable/j.ctv7h0ts6.8

[^13]:	Tarik Sabry. “The Propaganda Model after 20 Years: Interview with Edward S. Herman and Noam Chomsky.” Westminster Papers in Communication and Culture 6, no. 2 (June 1, 2017): 15. doi:10.16997/wpcc.121.

[^14]: Fuchs, 71–72.

[^15]:	Fuchs, 72.

[^16]:	Fuchs, 74.

[^17]:	Fuchs, 73.

[^18]:	Fuchs, 76.

[^19]:	Fuchs, 73.

[^20]:	Fuchs, 78.

[^21]:	Fuchs, 78.

[^22]:	Sabry, 14.

[^23]:	Fuchs, 81.

[^24]:	Fuchs, 72.

[^25]:	Fuchs, 84.

[^26]:	Prier, 52.

[^27]:	Prier, 52.

[^28]:	Prier, 52.

[^29]: Prier, 68–69.

[^30]:	Samantha Bradshaw and Philip N. Howard, 24.

[^31]:	Prier, 60.

[^32]:	Michael Bossetta. “The Weaponization of Social Media: Spear Phishing and Cyberattacks on Democracy.” Journal of International Affairs 71, no. 1.5 (2018): 102. https://www.jstor.org/stable/26508123.

[^33]:	Elizabeth Dubois, Sara Minaeian, Ariane Paquet-Labelle and Simon Beaudry. “Who to Trust on Social Media: How Opinion Leaders and Seekers Avoid Disinformation and Echo Chambers.” Social Media + Society, no. 3 (2020): 3, https://doi.org/10.1177/2056305120913993.

[^34]:	Del Vicario et al. “The Spreading of Misinformation Online.” Proceedings of the National Academy of Sciences of the United States of America 113, no. 3 (2016): 554. https://www.jstor.org/stable/26467425.

[^35]:	“Complete List of Subreddits.” frontpagemetrics. Accessed May 8, 2022.
https://frontpagemetrics.com/list-all-subreddits.

[^36]:	Vivian Roese, 327.

[^37]:	Dubois et al. 4.

[^38]:	Richard Rogers and Sabine Niederer, 42.

[^39]:	Christian Fuchs, 73.

[^40]:	Dubois et al. 8–9.

[^41]:	Dubois et al. 1.

[^42]:	Patricia L. Moravec, Randall K. Minas and Alan R. Dennis, 1350.

[^43]:	Dubois et al. 8.

[^44]:	Fuchs, 73.

[^45]:	Fuchs, 75.

[^46]:	Fuchs, 81.

[^47]:	Fuchs, 71.

[^48]:	Fuchs, 74.

[^49]:	Sommer Kapitan and David H. Silvera. “From Digital Media Influencers to Celebrity Endorsers: Attributions Drive Endorser Effectiveness.” Marketing Letters 27, no. 3 (2016): 554. http://www.jstor.org/stable/26179958.

[^50]:	Salma Jegham and Rym Bouzaabia. “Fashion Influencers on Instagram: Determinants and Impact of Opinion Leadership on Female Millennial Followers.” Journal of Consumer Behaviour 21, no 2 (2022): 6. doi:10.1002/cb.2050.

[^51]:	Sommer Kapitan and David H. Silvera, 554.

[^52]:	Salma Jegham and Rym Bouzaabia, 5.